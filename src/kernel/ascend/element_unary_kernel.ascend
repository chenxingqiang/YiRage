/* Copyright 2025 Chen Xingqiang (YiRage Project)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 * This file is part of YiRage (Yi Revolutionary AGile Engine)
 * 
 * Ascend Element Unary Kernel
 * 
 * Element-wise unary operations for Huawei Ascend NPU backend.
 * Optimized for Ascend's Vector Unit.
 */

#include "yirage/kernel/device_memory_manager.h"
#include "yirage/kernel/graph.h"
#include "yirage/kernel/operator.h"
#include "yirage/utils/ascend_helper.h"
#include "yirage/utils/fingerprint_functions.h"
#include <cassert>

#ifdef __ASCEND__
#include "acl/acl.h"
#endif

namespace yirage {
namespace kernel {

using namespace yirage::type;
using namespace yirage::config;
using namespace yirage::utils;

#ifdef YIRAGE_FINGERPRINT_USE_ASCEND

/**
 * @brief Compute element unary fingerprint on Ascend
 */
template <KNOperatorType OP_TYPE>
#ifdef __ASCEND__
__global__
#endif
void compute_element_unary_fingerprint_ascend(
    yirage::type::FPType *input_ptr,
    yirage::type::FPType *output_ptr,
    int num_elements,
    yirage::type::FPType *exp_table) {
  
#ifdef __ASCEND__
  int tid = threadIdx.x + blockIdx.x * blockDim.x;
  int stride = blockDim.x * gridDim.x;
#else
  int tid = 0;
  int stride = 1;
#endif
  
  for (int i = tid; i < num_elements; i += stride) {
    yirage::type::FPType x = input_ptr[i];
    yirage::type::FPType result;
    
    if constexpr (OP_TYPE == KN_EXP_OP) {
      result = compute_exp_fingerprint(x, exp_table);
    } else if constexpr (OP_TYPE == KN_SQUARE_OP) {
      result = compute_square_fingerprint(x);
    } else if constexpr (OP_TYPE == KN_SILU_OP) {
      result = compute_silu_fingerprint(x, exp_table);
    } else if constexpr (OP_TYPE == KN_RELU_OP) {
      result = compute_relu_fingerprint(x);
    } else if constexpr (OP_TYPE == KN_GELU_OP) {
      result = compute_gelu_fingerprint(x, exp_table);
    } else {
      result = x;
    }
    
    output_ptr[i] = result;
  }
}

bool KNElementUnaryOp::fingerprint(void) {
  assert(kgraph->gpu_dim.y == 1);
  assert(kgraph->gpu_dim.z == 1);
  
  yirage::kernel::DeviceMemoryManager *dmm =
      yirage::kernel::DeviceMemoryManager::get_instance();
  
#ifdef __ASCEND__
  checkACL(aclrtSetDevice(dmm->gpu_id));
#endif

  DTensor const &input = input_tensors[0];
  DTensor const &output = output_tensors[0];
  
  int num_elements = output.num_elements();
  
  int const num_threads_per_blk = 256;
  int num_blocks =
      (num_elements + num_threads_per_blk - 1) / num_threads_per_blk;
  
  for (int gpu_id = 0; gpu_id < kgraph->gpu_dim.x; gpu_id++) {
    yirage::type::FPType *input_ptr =
        reinterpret_cast<yirage::type::FPType *>(
            dmm->fp_base_ptr[gpu_id] + input.fp_offset);
    yirage::type::FPType *output_ptr =
        reinterpret_cast<yirage::type::FPType *>(
            dmm->fp_base_ptr[gpu_id] + output.fp_offset);
    
#ifdef __ASCEND__
    switch (op_type) {
      case KN_EXP_OP:
        compute_element_unary_fingerprint_ascend<KN_EXP_OP>
            <<<num_blocks, num_threads_per_blk>>>(
                input_ptr, output_ptr, num_elements, dmm->exp_lookup_table);
        break;
      case KN_SQUARE_OP:
        compute_element_unary_fingerprint_ascend<KN_SQUARE_OP>
            <<<num_blocks, num_threads_per_blk>>>(
                input_ptr, output_ptr, num_elements, dmm->exp_lookup_table);
        break;
      case KN_SILU_OP:
        compute_element_unary_fingerprint_ascend<KN_SILU_OP>
            <<<num_blocks, num_threads_per_blk>>>(
                input_ptr, output_ptr, num_elements, dmm->exp_lookup_table);
        break;
      case KN_RELU_OP:
        compute_element_unary_fingerprint_ascend<KN_RELU_OP>
            <<<num_blocks, num_threads_per_blk>>>(
                input_ptr, output_ptr, num_elements, dmm->exp_lookup_table);
        break;
      case KN_GELU_OP:
        compute_element_unary_fingerprint_ascend<KN_GELU_OP>
            <<<num_blocks, num_threads_per_blk>>>(
                input_ptr, output_ptr, num_elements, dmm->exp_lookup_table);
        break;
      default:
        return false;
    }
    checkACL(aclrtSynchronizeDevice());
#else
    // CPU fallback
    for (int i = 0; i < num_elements; i++) {
      FPType x = input_ptr[i];
      switch (op_type) {
        case KN_EXP_OP:
          output_ptr[i] = compute_exp_fingerprint(x, dmm->exp_lookup_table);
          break;
        case KN_SQUARE_OP:
          output_ptr[i] = compute_square_fingerprint(x);
          break;
        case KN_SILU_OP:
          output_ptr[i] = compute_silu_fingerprint(x, dmm->exp_lookup_table);
          break;
        case KN_RELU_OP:
          output_ptr[i] = compute_relu_fingerprint(x);
          break;
        case KN_GELU_OP:
          output_ptr[i] = compute_gelu_fingerprint(x, dmm->exp_lookup_table);
          break;
        default:
          output_ptr[i] = x;
      }
    }
#endif
  }
  return true;
}

#endif // YIRAGE_FINGERPRINT_USE_ASCEND

} // namespace kernel
} // namespace yirage

