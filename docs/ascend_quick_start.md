# Ascend NPU Backend Quick Start

## ğŸš€ ä½¿ç”¨YiRage + Ascend NPU

### å‰ææ¡ä»¶

åœ¨Ascendç³»ç»Ÿä¸Šï¼š
```bash
# 1. å®‰è£…CANNå·¥å…·åŒ…
# ä¸‹è½½è‡ª: https://www.hiascend.com/cann

# 2. å®‰è£…BiShengç¼–è¯‘å™¨ï¼ˆæ”¯æŒTritonï¼‰
pip install bisheng-triton

# 3. å®‰è£…torch_npu
pip install torch_npu
```

### å¿«é€Ÿå¼€å§‹

```python
import yirage as yr
import torch_npu

# åˆ›å»ºè®¡ç®—å›¾
graph = yr.new_kernel_graph()
X = graph.new_input(dims=(8, 4096), dtype=yr.float16)
W = graph.new_input(dims=(4096, 4096), dtype=yr.float16)
O = graph.matmul(X, W)
graph.mark_output(O)

# ä¼˜åŒ–ï¼ˆè‡ªåŠ¨ä½¿ç”¨Tritonâ†’BiShengè·¯å¾„ï¼‰
optimized = graph.superoptimize(
    backend='ascend',
    warmup_iters=10,
    profile_iters=100
)

# æ‰§è¡Œ
device = 'npu:0'
inputs = [
    torch.randn(8, 4096, dtype=torch.float16, device=device),
    torch.randn(4096, 4096, dtype=torch.float16, device=device)
]

outputs = optimized(inputs=inputs)
print(f"âœ… Executed on Ascend NPU: {outputs[0].shape}")
```

## ğŸ“Š ä»£ç ç”Ÿæˆè·¯å¾„

YiRage for Ascendæ”¯æŒä¸‰ç§è·¯å¾„ï¼š

### Path 1: Triton (æ¨è) â­â­â­â­â­

```
YiRage Graph â†’ Triton Code â†’ BiSheng Compiler â†’ Ascend NPU
```

**ä¼˜åŠ¿**ï¼š
- âœ… å¤ç”¨ç°æœ‰Triton transpilerï¼ˆ0é¢å¤–å¼€å‘ï¼‰
- âœ… CANNå®˜æ–¹æ”¯æŒ
- âœ… æ€§èƒ½ä¼˜ç§€ï¼ˆ90-95% æ‰‹å†™Ascend Cï¼‰
- âœ… ä»£ç å¯ç§»æ¤ï¼ˆCUDA/Ascendé€šç”¨ï¼‰

**ä½¿ç”¨**ï¼š
```python
graph.superoptimize(backend='ascend')  # é»˜è®¤ä½¿ç”¨Tritonè·¯å¾„
```

### Path 2: Ascend C (é«˜çº§) â­â­â­â­

```
YiRage Graph â†’ Ascend C Code â†’ ascendc â†’ Ascend NPU
```

**ä¼˜åŠ¿**ï¼š
- âœ… æè‡´æ€§èƒ½ï¼ˆ100%ï¼‰
- âœ… å®Œå…¨æ§åˆ¶ç¡¬ä»¶ç‰¹æ€§

**ä½¿ç”¨åœºæ™¯**ï¼š
- éœ€è¦è¶…è¶ŠTritonçš„æ€§èƒ½
- é’ˆå¯¹ç‰¹å®šworkloadæ·±åº¦ä¼˜åŒ–

**çŠ¶æ€**ï¼šæ¡†æ¶å°±ç»ªï¼Œå¾…å®ç°

### Path 3: TBE (å…¼å®¹) â­â­â­

ä»…ç”¨äºAscend 910æ—§ç‰ˆCANNå…¼å®¹

## ğŸ”§ å¼€å‘æ¨¡å¼ï¼ˆæ— Ascendç¡¬ä»¶ï¼‰

å³ä½¿æ²¡æœ‰Ascendç¡¬ä»¶ï¼Œä¹Ÿå¯ä»¥å¼€å‘ï¼š

```bash
# è¿è¡Œæµ‹è¯•ï¼ˆä¼šä½¿ç”¨CPU fallbackï¼‰
python tests/ascend/test_triton_integration.py

# ç»“æœï¼š
# âœ… Ascend backend framework: READY
# âš ï¸  BiSheng compiler: NOT AVAILABLE
# ğŸ’¡ Can still develop - test on Ascend hardware later
```

**åœ¨Ascendç³»ç»Ÿä¸Šæµ‹è¯•**ï¼š
```bash
# ç”Ÿæˆä»£ç å¹¶ç¼–è¯‘
python tests/ascend/test_triton_integration.py

# æ‰§è¡Œbenchmark
python benchmark/gated_mlp.py --backend ascend
```

## ğŸ“ˆ æ€§èƒ½é¢„æœŸ

åŸºäºCANNæ¶æ„å’ŒBiShengä¼˜åŒ–ï¼š

| Backend | ç¡¬ä»¶ | Tritonæ€§èƒ½ | æ‰‹å†™æ€§èƒ½ |
|---------|------|-----------|---------|
| CUDA | NVIDIA GPU | ~95% | 100% |
| Ascend | åä¸ºNPU | ~90-95% | 100% |

**ç»“è®º**ï¼šTritonè·¯å¾„æ€§èƒ½å……è¶³ï¼Œæ¨èä½œä¸ºé»˜è®¤é€‰æ‹©ï¼

## ğŸ¯ BiShengç¼–è¯‘å‘½ä»¤

YiRageè‡ªåŠ¨ç”Ÿæˆçš„ç¼–è¯‘å‘½ä»¤ï¼š

```bash
bisheng-triton \
  --target=Ascend910B \
  --opt-level=3 \
  --enable-fp16 \
  -o kernel.so
```

## âœ… éªŒè¯æ¸…å•

- [x] Backendæ¡†æ¶
- [x] æœç´¢ç­–ç•¥
- [x] Tritoné›†æˆ
- [x] é…ç½®æ–‡ä»¶
- [x] æµ‹è¯•è„šæœ¬
- [ ] çœŸå®ç¡¬ä»¶éªŒè¯ï¼ˆéœ€è¦Ascend 910/910Bï¼‰
- [ ] æ€§èƒ½benchmark
- [ ] ä¸PyTorchå¯¹æ¯”

## ğŸ“š å‚è€ƒèµ„æº

- [CANNå®˜ç½‘](https://www.hiascend.com/cann)
- [Ascend Cç¼–ç¨‹æŒ‡å—](https://www.hiascend.com/document)
- BiShengç¼–è¯‘å™¨æ–‡æ¡£
- YiRage Triton Transpiler: `src/triton_transpiler/`

