# Ascend NPU Backend Implementation Guide

This document provides a comprehensive technical guide for implementing and using the Huawei Ascend NPU backend in YiRage.

## Executive Summary

**Key Discovery: CANN Natively Supports Triton!**

Based on [Huawei CANN documentation](https://www.hiascend.com/cann) and the [triton-ascend](https://github.com/Ascend/triton-ascend) project, the BiSheng compiler provides native Triton language support, enabling direct code generation path reuse.

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#e3f2fd', 'lineColor': '#546e7a'}}}%%
graph TB
    subgraph FRAMEWORKS["üî∑ AI Frameworks"]
        A["<b>PyTorch</b> / <b>TensorFlow</b> / <b>MindSpore</b>"]
    end

    subgraph CANN["üî∂ CANN Architecture"]
        B["<b>Programming Languages</b>"]
        C["<b>BiSheng Compiler</b><br/><i>Heterogeneous Optimization</i>"]
        D["<b>Runtime + Driver</b><br/><i>ACL API</i>"]
        B --> C --> D
    end

    subgraph OPTIONS["üìã Programming Options"]
        E["Ascend C<br/><i>Native API + CATLASS</i>"]
        F["<b>Triton ‚≠ê</b><br/><i>BiSheng Support</i>"]
        G["TBE<br/><i>Tensor Boost Engine</i>"]
    end

    subgraph HARDWARE["üñ•Ô∏è Hardware"]
        H["<b>Ascend AI Processor</b><br/>910 / 910B / 310P"]
    end

    A --> B
    E & F & G --> B
    D --> H

    style FRAMEWORKS fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style CANN fill:#fff8e1,stroke:#ffa000,stroke-width:2px
    style OPTIONS fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style HARDWARE fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    style F fill:#c8e6c9,stroke:#2e7d32,stroke-width:2px
```

## Key Insights

### 1. Native Triton Support in CANN

According to Huawei documentation: *"BiSheng Compiler supports Triton and other third-party programming languages"*

**Implications for YiRage:**

| Advantage | Description |
|-----------|-------------|
| ‚úÖ Code Reuse | Existing `triton_transpiler` can be directly leveraged |
| ‚úÖ Compilation Path | Triton Code ‚Üí BiSheng Compiler ‚Üí Ascend NPU |
| ‚úÖ Reduced Development | No need to implement complete Ascend C code generation |
| ‚úÖ Optimization | Automatic access to all Triton optimizations |

### 2. Code Generation Paths

| Path | Language | Compiler | Current Status |
|------|----------|----------|----------------|
| **Triton** | Python DSL | BiSheng | ‚úÖ Framework Ready |
| **Ascend C** | C-like | ascendc | ‚è≥ Stub Implementation |
| **TBE** | Python | tbe-compiler | ‚è≥ Stub Implementation |

## Architecture Overview

### Ascend NPU Hardware Characteristics

| Component | Ascend 910 | Ascend 910B | Ascend 310P |
|-----------|------------|-------------|-------------|
| AI Cores | 32 | 32 | 8 |
| HBM Capacity | 32 GB | 64 GB | 8 GB |
| L1 Buffer/Core | 256 KB | 512 KB | 128 KB |
| Cube Unit | 16√ó16 tiles | 16√ó16 tiles | 16√ó16 tiles |
| Peak FP16 TFLOPS | 320 | 400 | 80 |

### Search Configuration Mapping

Unlike CUDA (32-thread warps) or MACA (64-thread warps), Ascend uses **AI Core parallelism**:

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#e3f2fd', 'lineColor': '#546e7a'}}}%%
flowchart LR
    subgraph CUDA["üü¢ NVIDIA CUDA Model"]
        direction TB
        A1["<b>Grid</b>"] --> A2["<b>Block</b>"]
        A2 --> A3["<b>Warp</b><br/><i>32 threads</i>"]
        A3 --> A4["Thread"]
    end

    subgraph ASCEND["üî¥ Huawei Ascend Model"]
        direction TB
        B1["<b>Task</b>"] --> B2["<b>AI Core Block</b>"]
        B2 --> B3["<b>Cube Unit</b><br/><i>16√ó16 matrix</i>"]
        B2 --> B4["<b>Vector Unit</b><br/><i>element-wise</i>"]
    end

    style CUDA fill:#e8f5e9,stroke:#2e7d32,stroke-width:2px
    style ASCEND fill:#ffebee,stroke:#c62828,stroke-width:2px
    style A3 fill:#c8e6c9,stroke:#388e3c,stroke-width:2px
    style B3 fill:#ffcdd2,stroke:#d32f2f,stroke-width:2px
    style B4 fill:#ffe0b2,stroke:#ef6c00,stroke-width:2px
```

## Implementation Status

### ‚úÖ Completed Components

#### 1. Backend Framework (`src/backend/ascend_backend.cc`)

```cpp
class AscendBackend : public BackendInterface {
public:
    std::string get_name() const override { return "ascend"; }
    type::BackendType get_type() const override { return type::BT_ASCEND; }
    bool is_available() const override;
    size_t get_device_memory() const override;
    // ... device detection and memory queries
};
```

#### 2. Search Strategy (`src/search/backend_strategies/ascend_strategy.cc`)

- AI Core configuration generation
- Cube operation optimization (16√ó16 tile alignment)
- L1 buffer utilization evaluation
- Vector/Cube operation selection

#### 3. Python Configuration (`python/yirage/ascend_config.py`)

```python
def get_ascend_search_config():
    return {
        "grid_dims_to_explore": [
            (1, 1, 1), (2, 1, 1), (4, 1, 1), (8, 1, 1),
            (16, 1, 1), (32, 1, 1),  # Up to 32 AI Cores
        ],
        "block_dims_to_explore": [
            (1, 1, 1), (2, 1, 1), (4, 1, 1), (8, 1, 1),
        ],
        "fmaps_to_explore": [-1, 0, 1, 2],
        "franges_to_explore": [4, 8, 16],  # Cube-friendly
    }
```

#### 4. Triton Integration (`include/yirage/triton_transpiler/transpile.h`)

```cpp
struct TritonTranspilerConfig {
    int target_cc;
    bool is_ascend_target = false;      // Ascend target flag
    std::string ascend_soc = "Ascend910B";  // SOC specification
};
```

#### 5. Device Memory Manager (`src/kernel/ascend/device_memory_manager.cc`)

- ACL runtime initialization
- Device memory allocation via `aclrtMalloc`
- Host-device memory transfers
- Stream management

### ‚è≥ Pending (Requires Ascend Hardware)

| Component | Current State | Required Action |
|-----------|---------------|-----------------|
| BiSheng Compilation | Triton code generation | Invoke BiSheng compiler |
| End-to-End Execution | Framework ready | Hardware validation |
| Performance Tuning | Basic search strategy | Post-benchmark optimization |

## Code Structure

### File Organization

```
YiRage/
‚îú‚îÄ‚îÄ include/yirage/
‚îÇ   ‚îú‚îÄ‚îÄ kernel/ascend/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ascend_kernel_config.h    # Kernel configuration
‚îÇ   ‚îú‚îÄ‚îÄ search/backend_strategies/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ascend_strategy.h         # Search strategy header
‚îÇ   ‚îî‚îÄ‚îÄ triton_transpiler/
‚îÇ       ‚îî‚îÄ‚îÄ transpile.h               # Triton config with Ascend support
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ascend_backend.cc         # Backend implementation
‚îÇ   ‚îú‚îÄ‚îÄ kernel/ascend/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ device_memory_manager.cc  # ACL memory management (Host-side)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ascend_fingerprint_kernels.cc
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ascend_kernel_generator.cc
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ascend_optimizer.cc
‚îÇ   ‚îú‚îÄ‚îÄ search/backend_strategies/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ascend_strategy.cc        # Search strategy implementation
‚îÇ   ‚îî‚îÄ‚îÄ transpiler/
‚îÇ       ‚îî‚îÄ‚îÄ ascend_transpiler_stub.cc # Transpiler stub
‚îú‚îÄ‚îÄ python/yirage/
‚îÇ   ‚îî‚îÄ‚îÄ ascend_config.py              # Python search configuration
‚îî‚îÄ‚îÄ tests/ascend/
    ‚îú‚îÄ‚îÄ test_superoptimize.py         # Optimization tests
    ‚îî‚îÄ‚îÄ test_triton_integration.py    # Triton integration tests
```

### Search Configuration Display

When using Ascend backend, the search configuration displays:

```
========== Search Configuration ==========
  backend_type: ASCEND (4)
  architecture: Huawei Ascend NPU (AI Core based)
  parallelism: AI Core blocks (no warp concept)
  cube_unit: 16x16 matrix tiles
  max num threadblock graph op: 8
  max num kernel_graph op: 5
  search_thread: 24
  grid dims to explore:
    (1, 1, 1), (2, 1, 1), (4, 1, 1), ...
```

## Usage Guide

### Basic Usage

```python
import yirage as yr

# Create computation graph
graph = yr.new_kernel_graph()
X = graph.new_input(dims=(8, 64), dtype=yr.float16)
W = graph.new_input(dims=(64, 64), dtype=yr.float16)
O = graph.matmul(X, W)
graph.mark_output(O)

# Run superoptimize with Ascend backend
# Note: Full execution requires Ascend hardware
optimized = graph.superoptimize(backend='ascend')
```

### Ascend System Setup

```bash
# 1. Environment setup
source /usr/local/Ascend/ascend-toolkit/set_env.sh
export LD_LIBRARY_PATH=/usr/local/Ascend/driver/lib64:$LD_LIBRARY_PATH

# 2. Install dependencies
pip install torch-npu triton-ascend

# 3. Build YiRage with Ascend support
export USE_ASCEND=ON USE_CUDA=OFF USE_MACA=OFF
pip install -e . --no-build-isolation

# 4. Run tests
python tests/ascend/test_superoptimize.py

# 5. Run benchmarks
python benchmark/gated_mlp.py --backend ascend
```

## Performance Expectations

Based on Huawei official benchmarks and BiSheng compiler optimizations:

| Workload | PyTorch-NPU Baseline | YiRage (Ascend) | Expected Speedup |
|----------|----------------------|-----------------|------------------|
| MatMul | 1.0√ó | 1.5‚Äì2.0√ó | **50‚Äì100%** |
| Attention | 1.0√ó | 2.0‚Äì3.0√ó | **100‚Äì200%** |
| Gated MLP | 1.0√ó | 1.8‚Äì2.5√ó | **80‚Äì150%** |

### YiRage Optimization Advantages

| Optimization | Description |
|--------------|-------------|
| **Kernel Fusion** | Combines multiple operations into single kernel |
| **Search-Based Config** | Explores optimal AI Core configurations |
| **L1 Buffer Optimization** | Maximizes on-chip memory utilization |
| **Cube Unit Utilization** | Ensures 16√ó16 tile alignment for matrix ops |

## Implementation Checklist

### Completed

- [x] Backend type definition (`BT_ASCEND` in `type.h`)
- [x] Backend interface implementation (`ascend_backend.cc`)
- [x] Search strategy implementation (`ascend_strategy.cc`)
- [x] Python configuration (`ascend_config.py`)
- [x] Triton transpiler configuration extension
- [x] Device memory manager (Host-side ACL)
- [x] Test framework
- [x] Documentation

### Pending (Requires Ascend Environment)

- [ ] BiSheng compiler integration
- [ ] End-to-end execution validation
- [ ] Performance benchmarking
- [ ] Cube operation profiling

## References

| Resource | URL |
|----------|-----|
| CANN Official | https://www.hiascend.com/cann |
| torch_npu | https://github.com/Ascend/pytorch |
| triton-ascend | https://github.com/Ascend/triton-ascend |
| Ascend Documentation | https://www.hiascend.com/document |
| CATLASS (Ascend CUTLASS) | https://github.com/Ascend/catlass |

## Troubleshooting

### Common Issues

| Issue | Solution |
|-------|----------|
| `libhccl.so not found` | `source /usr/local/Ascend/ascend-toolkit/set_env.sh` |
| `npu-smi error` | Add driver libs: `export LD_LIBRARY_PATH=/usr/local/Ascend/driver/lib64:$LD_LIBRARY_PATH` |
| `CMake < 3.24` | `pip install "cmake>=3.24"` |
| `triton not found` | `pip install triton-ascend` |

### Environment Verification

```bash
# Check NPU availability
npu-smi info -l

# Verify CANN installation
python -c "import torch_npu; print(torch_npu.npu.is_available())"

# Check YiRage Ascend backend
python -c "import yirage; print('ascend' in yirage.get_available_backends())"
```
