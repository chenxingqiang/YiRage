# MPSæœç´¢ç­–ç•¥åˆ†æä¸ä¼˜åŒ–å»ºè®®

## ğŸ“Š å½“å‰å®ç°åˆ†æ

### âœ… åšå¾—å¥½çš„åœ°æ–¹

1. **æ­£ç¡®çš„åŸºç¡€æ¶æ„** âœ…
   - æ­£ç¡®è¯†åˆ«SIMD width = 32
   - threadgroup memory = 32KB (å‡†ç¡®)
   - çº¿ç¨‹æ•°é™åˆ¶ 32-1024 (æ­£ç¡®)

2. **å¤šç»´åº¦è¯„ä¼°** âœ…
   ```cpp
   float score = 0.4f * gpu_util_score + 
                 0.3f * memory_score +
                 0.3f * tg_memory_score;
   ```
   æƒé‡åˆ†é…åˆç†

3. **åŸºç¡€éªŒè¯** âœ…
   - æ£€æŸ¥threadgroupå¤§å°æ˜¯å¦ä¸ºSIMD widthçš„å€æ•°
   - æ£€æŸ¥tileå¤§å°æœ‰æ•ˆæ€§

### âŒ å­˜åœ¨çš„é—®é¢˜å’Œæ”¹è¿›æœºä¼š

---

## ğŸ”´ é—®é¢˜1: Threadgroupé…ç½®ç”Ÿæˆè¿‡äºç®€å•

### å½“å‰å®ç°
```cpp
std::vector<int> MPSSearchStrategy::generate_threadgroup_configs(
    size_t problem_size) {
  std::vector<int> configs;
  int simd_width = 32;
  for (int mult = 4; mult <= 32; mult *= 2) {  // åªå°è¯•4, 8, 16, 32å€
    int size = simd_width * mult;
    if (size <= 1024) {
      configs.push_back(size);
    }
  }
  return configs;  // åªæœ‰4ä¸ªå€™é€‰: 128, 256, 512, 1024
}
```

### é—®é¢˜
- **æœç´¢ç©ºé—´å¤ªå°**: åªæœ‰4ä¸ªå€™é€‰å€¼
- **å¿½ç•¥é—®é¢˜ç‰¹æ€§**: ä¸è€ƒè™‘å®é™…problem_size
- **ç¼ºå°‘ç»†ç²’åº¦**: è·³è¿‡äº†64, 96, 160, 192, 224, 288, 320...ç­‰æœ‰æ•ˆå€¼

### æ”¹è¿›æ–¹æ¡ˆ
```cpp
std::vector<int> generate_threadgroup_configs(size_t problem_size) {
  std::vector<int> configs;
  int simd_width = 32;
  
  // åŸºäºproblem_sizeåŠ¨æ€è°ƒæ•´èŒƒå›´
  int min_mult = (problem_size < 1024) ? 2 : 4;      // å°é—®é¢˜ç”¨æ›´å°çš„threadgroup
  int max_mult = (problem_size > 1048576) ? 32 : 16; // å¤§é—®é¢˜ç”¨æ›´å¤§çš„threadgroup
  
  // ç”Ÿæˆæ›´å¤šå€™é€‰å€¼ï¼ˆæ‰€æœ‰SIMD widthçš„å€æ•°ï¼‰
  for (int mult = min_mult; mult <= max_mult; mult++) {
    int size = simd_width * mult;
    if (size >= 32 && size <= 1024) {
      configs.push_back(size);
    }
  }
  
  // ç‰¹åˆ«æ·»åŠ ä¸€äº›ç»éªŒä¼˜åŒ–çš„å€¼
  std::vector<int> special = {64, 96, 128, 192, 256, 320, 512};
  for (int s : special) {
    if (s % simd_width == 0 && s >= 32 && s <= 1024) {
      if (std::find(configs.begin(), configs.end(), s) == configs.end()) {
        configs.push_back(s);
      }
    }
  }
  
  std::sort(configs.begin(), configs.end());
  return configs;  // ç°åœ¨æœ‰10-20ä¸ªå€™é€‰å€¼
}
```

**æ”¹è¿›æ•ˆæœ**: æœç´¢ç©ºé—´ä»4ä¸ªå¢åŠ åˆ°10-20ä¸ªï¼Œè¦†ç›–æ›´ç»†ç²’åº¦çš„é…ç½®

---

## ğŸ”´ é—®é¢˜2: Tileé…ç½®ä¸å¤Ÿçµæ´»

### å½“å‰å®ç°
```cpp
std::vector<std::tuple<int, int, int>>
MPSSearchStrategy::generate_tile_configs(int m, int n, int k) {
  std::vector<std::tuple<int, int, int>> configs;
  std::vector<int> tile_sizes = {16, 32, 48, 64};  // å›ºå®š4ä¸ªå€¼
  
  for (int tile : tile_sizes) {
    configs.emplace_back(
        std::min(m, tile),
        std::min(n, tile),
        std::min(k, tile));
  }
  return configs;  // åªæœ‰4ä¸ªå€™é€‰
}
```

### é—®é¢˜
- **tileå¤§å°å•ä¸€**: æ‰€æœ‰ç»´åº¦ä½¿ç”¨ç›¸åŒtile
- **ä¸è€ƒè™‘threadgroup memory**: 32KBé™åˆ¶æ²¡æœ‰ä½“ç°
- **å¿½ç•¥çŸ©é˜µå½¢çŠ¶**: ä¸è€ƒè™‘m, n, kçš„ç›¸å¯¹å¤§å°
- **ç¼ºå°‘å¤§tile**: æœ€å¤§æ‰64ï¼Œå¯¹äºå¤§çŸ©é˜µä¸å¤Ÿ

### æ”¹è¿›æ–¹æ¡ˆ
```cpp
std::vector<std::tuple<int, int, int>>
generate_tile_configs(int m, int n, int k) {
  std::vector<std::tuple<int, int, int>> configs;
  
  // Threadgroup memory = 32KB = 32768 bytes
  const size_t tg_memory = 32 * 1024;
  const size_t fp16_size = 2;  // float16
  
  // å°è¯•ä¸åŒçš„tileå¤§å°ç»„åˆ
  std::vector<int> tile_m_sizes = {16, 32, 48, 64, 96, 128};
  std::vector<int> tile_n_sizes = {16, 32, 48, 64, 96, 128};
  std::vector<int> tile_k_sizes = {8, 16, 24, 32, 48, 64};
  
  for (int tm : tile_m_sizes) {
    for (int tn : tile_n_sizes) {
      for (int tk : tile_k_sizes) {
        // è·³è¿‡è¶…å‡ºç»´åº¦çš„é…ç½®
        if (tm > m || tn > n || tk > k) continue;
        
        // è®¡ç®—éœ€è¦çš„threadgroup memory
        // A: tm x tk, B: tk x tn, C: tm x tn
        size_t memory_needed = (tm * tk + tk * tn + tm * tn) * fp16_size;
        
        // ç¡®ä¿ä¸è¶…è¿‡threadgroup memory (ç•™20%ä½™é‡)
        if (memory_needed > tg_memory * 0.8) continue;
        
        // åå¥½å¹³è¡¡çš„tileé…ç½®
        float balance_score = 1.0f - std::abs(
            static_cast<float>(tm * tn) / (tk * tk) - 1.0f);
        
        if (balance_score > 0.5f) {  // åªä¿ç•™ç›¸å¯¹å¹³è¡¡çš„é…ç½®
          configs.emplace_back(
              std::min(m, tm),
              std::min(n, tn),
              std::min(k, tk));
        }
      }
    }
  }
  
  // è‡³å°‘è¿”å›ä¸€ä¸ªæœ‰æ•ˆé…ç½®
  if (configs.empty()) {
    configs.emplace_back(
        std::min(m, 32),
        std::min(n, 32),
        std::min(k, 32));
  }
  
  // å»é‡
  std::sort(configs.begin(), configs.end());
  configs.erase(std::unique(configs.begin(), configs.end()), configs.end());
  
  return configs;  // ç°åœ¨å¯èƒ½æœ‰å‡ åä¸ªå€™é€‰
}
```

**æ”¹è¿›æ•ˆæœ**: 
- è€ƒè™‘äº†å®é™…å†…å­˜é™åˆ¶
- tileä¸å†å¼ºåˆ¶æ­£æ–¹å½¢
- è‡ªåŠ¨é€‚åº”çŸ©é˜µå½¢çŠ¶

---

## ğŸ”´ é—®é¢˜3: GPUåˆ©ç”¨ç‡è¯„ä¼°è¿‡äºç®€åŒ–

### å½“å‰å®ç°
```cpp
float MPSSearchStrategy::evaluate_gpu_utilization(
    kernel::mps::MPSKernelConfig const &config) {
  int total_threads = config.get_total_blocks() *
                     config.threads_per_threadgroup;
  
  // å‡è®¾æ¯ä¸ªGPUæ ¸å¿ƒå¯ä»¥å¤„ç†~1024çº¿ç¨‹
  int ideal_threads = gpu_cores_ * 1024;
  
  float utilization = std::min(1.0f, 
      static_cast<float>(total_threads) / ideal_threads);
  
  return utilization;
}
```

### é—®é¢˜
- **1024å€æ•°æ˜¯é”™è¯¯çš„**: Apple GPUä¸æ˜¯è¿™æ ·å·¥ä½œçš„
- **æœªè€ƒè™‘GPUå˜ä½“**: M1åŸºç¡€ç‰ˆ(8æ ¸) vs M3 Max(40æ ¸)å·®å¼‚å·¨å¤§
- **å¿½ç•¥occupancy**: ä¸è€ƒè™‘å®é™…å¹¶å‘threadgroupæ•°
- **ç¼ºå°‘å¸¦å®½è€ƒè™‘**: ç»Ÿä¸€å†…å­˜æ¶æ„çš„ç‰¹æ€§æœªä½“ç°

### æ”¹è¿›æ–¹æ¡ˆ
```cpp
float evaluate_gpu_utilization(kernel::mps::MPSKernelConfig const &config) {
  // Apple GPUæ¶æ„ç‰¹ç‚¹ï¼š
  // - æ¯ä¸ªGPUæ ¸å¿ƒæ˜¯ä¸€ä¸ªå®Œæ•´çš„è®¡ç®—å•å…ƒ
  // - æ¯ä¸ªæ ¸å¿ƒå¯ä»¥å¹¶å‘æ‰§è¡Œå¤šä¸ªthreadgroup
  // - ç»Ÿä¸€å†…å­˜æ¶æ„ï¼Œå†…å­˜è®¿é—®å…±äº«
  
  int num_threadgroups = config.get_total_blocks();
  int threads_per_tg = config.threads_per_threadgroup;
  int num_simd_groups = (threads_per_tg + 31) / 32;
  
  // ä¼°ç®—æ¯ä¸ªGPUæ ¸å¿ƒå¯ä»¥å¹¶å‘çš„threadgroupæ•°
  // åŸºäºthreadgroup memoryä½¿ç”¨æƒ…å†µ
  size_t tg_memory_used = (config.tile_m * config.tile_k +
                           config.tile_k * config.tile_n +
                           config.tile_m * config.tile_n) * sizeof(float);
  size_t tg_memory_available = 32 * 1024;
  int max_concurrent_tg_per_core = 
      std::max(1, static_cast<int>(tg_memory_available / tg_memory_used));
  
  // M1/M2/M3æœ‰ä¸åŒçš„å¹¶å‘èƒ½åŠ›
  // æ ¹æ®GPU familyè°ƒæ•´
  float concurrency_factor = 1.0f;
  switch (config.gpu_family) {
    case 7:  // M1
      concurrency_factor = 4.0f;  // æ¯æ ¸å¿ƒçº¦4ä¸ªå¹¶å‘threadgroup
      break;
    case 8:  // M2
      concurrency_factor = 6.0f;  // æ”¹è¿›çš„è°ƒåº¦
      break;
    case 9:  // M3
      concurrency_factor = 8.0f;  // æ›´å¥½çš„å¹¶å‘æ€§
      break;
    default:
      concurrency_factor = 4.0f;
  }
  
  max_concurrent_tg_per_core = std::min(
      max_concurrent_tg_per_core,
      static_cast<int>(concurrency_factor));
  
  // ç†æƒ³æƒ…å†µä¸‹ï¼Œæœ‰è¶³å¤Ÿçš„threadgroupå¡«æ»¡æ‰€æœ‰GPUæ ¸å¿ƒ
  int ideal_threadgroups = gpu_cores_ * max_concurrent_tg_per_core;
  
  // è®¡ç®—åˆ©ç”¨ç‡
  float utilization = std::min(1.0f,
      static_cast<float>(num_threadgroups) / ideal_threadgroups);
  
  // å¥–åŠ±ä½¿ç”¨åˆç†å¤§å°çš„threadgroup (192-512æœ€ä¼˜)
  float size_bonus = 1.0f;
  if (threads_per_tg >= 192 && threads_per_tg <= 512) {
    size_bonus = 1.1f;
  } else if (threads_per_tg < 64 || threads_per_tg > 768) {
    size_bonus = 0.9f;
  }
  
  return utilization * size_bonus;
}
```

**æ”¹è¿›æ•ˆæœ**: æ›´å‡†ç¡®åæ˜ Apple Siliconçš„å¹¶å‘ç‰¹æ€§

---

## ğŸ”´ é—®é¢˜4: å†…å­˜æ•ˆç‡è¯„ä¼°ä¸å¤Ÿæ·±å…¥

### å½“å‰å®ç°
```cpp
float MPSSearchStrategy::evaluate_memory_efficiency(
    kernel::mps::MPSKernelConfig const &config) {
  float pattern_score = 1.0f;
  
  switch (config.access_pattern) {
  case kernel::mps::MemoryPattern::COALESCED:
    pattern_score = 1.0f; // Best
    break;
  case kernel::mps::MemoryPattern::TILED:
    pattern_score = 0.85f; // Good
    break;
  case kernel::mps::MemoryPattern::STRIDED:
    pattern_score = 0.7f; // Acceptable
    break;
  }
  
  return pattern_score;
}
```

### é—®é¢˜
- **ä»…è€ƒè™‘pattern**: å¿½ç•¥å®é™…æ•°æ®å¤§å°å’Œè®¿é—®æ¬¡æ•°
- **æœªåˆ©ç”¨ç»Ÿä¸€å†…å­˜**: Apple Siliconçš„ç»Ÿä¸€å†…å­˜æ¶æ„ç‰¹æ€§
- **ç¼ºå°‘å¸¦å®½ä¼°ç®—**: ä¸è€ƒè™‘å†…å­˜å¸¦å®½åˆ©ç”¨ç‡
- **å¿½ç•¥ç¼“å­˜**: GPU L1/L2ç¼“å­˜å½±å“

### æ”¹è¿›æ–¹æ¡ˆ
```cpp
float evaluate_memory_efficiency(kernel::mps::MPSKernelConfig const &config) {
  // åŸºç¡€patternåˆ†æ•°
  float pattern_score = 1.0f;
  switch (config.access_pattern) {
  case kernel::mps::MemoryPattern::COALESCED:
    pattern_score = 1.0f;
    break;
  case kernel::mps::MemoryPattern::TILED:
    pattern_score = 0.90f;  // Tiledå…¶å®å¾ˆé€‚åˆApple GPU
    break;
  case kernel::mps::MemoryPattern::STRIDED:
    pattern_score = 0.75f;
    break;
  }
  
  // ç»Ÿä¸€å†…å­˜æ¶æ„å¥–åŠ±ï¼šå¤§tileå¯ä»¥æ›´å¥½åˆ©ç”¨å¸¦å®½
  size_t tile_size = config.tile_m * config.tile_n * config.tile_k;
  float bandwidth_score = 1.0f;
  if (tile_size >= 16384) {  // 16K elements
    bandwidth_score = 1.1f;  // å¤§æ•°æ®ä¼ è¾“æ›´é«˜æ•ˆ
  } else if (tile_size < 1024) {
    bandwidth_score = 0.9f;  // å°æ•°æ®ä¼ è¾“æœ‰overhead
  }
  
  // Threadgroup memoryé‡ç”¨ç‡
  // æ•°æ®åœ¨threadgroup memoryä¸­åœç•™è¶Šä¹…è¶Šå¥½
  float reuse_factor = static_cast<float>(config.tile_k) /
                      std::sqrt(config.tile_m * config.tile_n);
  float reuse_score = std::min(1.0f, reuse_factor);
  
  // Mç³»åˆ—ä¸åŒçš„å†…å­˜å¸¦å®½
  float bandwidth_multiplier = 1.0f;
  switch (config.gpu_family) {
  case 7:  // M1: 68.25 GB/s
    bandwidth_multiplier = 0.9f;
    break;
  case 8:  // M2: 100 GB/s
    bandwidth_multiplier = 1.0f;
    break;
  case 9:  // M3: 100+ GB/s
    bandwidth_multiplier = 1.05f;
    break;
  }
  
  return (pattern_score * 0.4f +
          bandwidth_score * 0.3f +
          reuse_score * 0.3f) * bandwidth_multiplier;
}
```

**æ”¹è¿›æ•ˆæœ**: è€ƒè™‘äº†ç»Ÿä¸€å†…å­˜æ¶æ„å’Œå®é™…å¸¦å®½ç‰¹æ€§

---

## ğŸ”´ é—®é¢˜5: Threadgroup Memoryè¯„ä¼°è®¡ç®—é”™è¯¯

### å½“å‰å®ç°
```cpp
float MPSSearchStrategy::evaluate_threadgroup_memory(
    kernel::mps::MPSKernelConfig const &config) {
  // è®¡ç®—æœ‰é—®é¢˜ï¼
  size_t required_memory = (config.tile_m * config.tile_k +
                           config.tile_k * config.tile_n +
                           config.tile_m * config.tile_n) *
                          sizeof(float);  // â† è¿™é‡Œåº”è¯¥æ˜¯sizeof(float16)
                          
  float memory_ratio = static_cast<float>(required_memory) /
                      config.threadgroup_memory_size;
  
  // è¯„åˆ†é€»è¾‘ä¹Ÿæœ‰é—®é¢˜
  float score = 1.0f - std::abs(1.0f - memory_ratio);
  return std::max(0.0f, score);
}
```

### é—®é¢˜
- **æ•°æ®ç±»å‹é”™è¯¯**: ä½¿ç”¨`sizeof(float)`è€Œä¸æ˜¯å®é™…çš„float16
- **è¯„åˆ†é€»è¾‘ä¸åˆç†**: ä½¿ç”¨è¶Šæ¥è¿‘100%è¶Šå¥½ï¼Ÿå®é™…ä¸Š70-80%æœ€ä¼˜
- **æœªè€ƒè™‘ä¸­é—´ç»“æœ**: å¯èƒ½éœ€è¦é¢å¤–ä¸´æ—¶ç©ºé—´
- **ç¼ºå°‘å®‰å…¨è¾¹ç•Œ**: æ²¡æœ‰ç•™ä½™é‡ç»™ç³»ç»Ÿä½¿ç”¨

### æ”¹è¿›æ–¹æ¡ˆ
```cpp
float evaluate_threadgroup_memory(kernel::mps::MPSKernelConfig const &config) {
  // ä½¿ç”¨æ­£ç¡®çš„æ•°æ®ç±»å‹å¤§å°
  const size_t dtype_size = 2;  // float16 = 2 bytes
  
  // è®¡ç®—å®é™…éœ€è¦çš„memory
  // Matrix A: tile_m x tile_k
  // Matrix B: tile_k x tile_n  
  // Matrix C: tile_m x tile_n (accumulation)
  size_t memory_a = config.tile_m * config.tile_k * dtype_size;
  size_t memory_b = config.tile_k * config.tile_n * dtype_size;
  size_t memory_c = config.tile_m * config.tile_n * sizeof(float);  // Cç”¨floatç´¯åŠ 
  
  // å¯èƒ½éœ€è¦çš„ä¸´æ—¶ç©ºé—´ (å¦‚reduceæ“ä½œ)
  size_t temp_memory = config.threads_per_threadgroup * sizeof(float);
  
  size_t total_required = memory_a + memory_b + memory_c + temp_memory;
  
  // Apple Silicon: 32KB threadgroup memory
  const size_t tg_memory = 32 * 1024;
  
  // å¦‚æœè¶…å‡ºé™åˆ¶ï¼Œç›´æ¥è¿”å›0
  if (total_required > tg_memory) {
    return 0.0f;
  }
  
  // è®¡ç®—åˆ©ç”¨ç‡
  float utilization = static_cast<float>(total_required) / tg_memory;
  
  // æœ€ä¼˜èŒƒå›´ï¼š60-80% (ç•™ä½™é‡ç»™ç³»ç»Ÿï¼Œä½†ä¹Ÿä¸è¦æµªè´¹)
  float score = 1.0f;
  if (utilization >= 0.60f && utilization <= 0.80f) {
    score = 1.0f;  // ç†æƒ³èŒƒå›´
  } else if (utilization > 0.80f && utilization <= 0.95f) {
    score = 0.9f - (utilization - 0.80f) * 2.0f;  // è¶…è¿‡80%å¼€å§‹æƒ©ç½š
  } else if (utilization < 0.60f) {
    score = 0.7f + utilization * 0.5f;  // åˆ©ç”¨ç‡å¤ªä½ä¹Ÿä¸å¥½
  } else {
    score = 0.5f;  // è¶…è¿‡95%ï¼Œå¤ªå±é™©
  }
  
  // å¦‚æœtileé…ç½®èƒ½æ•´é™¤threadgroupï¼Œç»™äºˆå¥–åŠ±
  int threads_needed = (config.tile_m * config.tile_n + 31) / 32 * 32;
  if (threads_needed == config.threads_per_threadgroup) {
    score *= 1.1f;
  }
  
  return std::min(1.0f, score);
}
```

**æ”¹è¿›æ•ˆæœ**: 
- ä¿®æ­£è®¡ç®—é”™è¯¯
- æ›´åˆç†çš„è¯„åˆ†é€»è¾‘
- è€ƒè™‘å®é™…å·¥ç¨‹çº¦æŸ

---

## ğŸ”´ é—®é¢˜6: GPUæ ¸å¿ƒæ•°æ£€æµ‹ä¸å‡†ç¡®

### å½“å‰å®ç°
```cpp
int MPSOptimizer::get_gpu_core_count() {
  int family = detect_gpu_family();
  
  switch (family) {
  case 7:  // M1
    return 8;   // M1 has 7-8 GPU cores (base)
  case 8:  // M2
    return 10;  // M2 has 8-10 GPU cores (base)
  case 9:  // M3
    return 10;  // M3 has 10+ GPU cores (base)
  default:
    return 8;
  }
}
```

### é—®é¢˜
- **å¿½ç•¥Pro/Max/Ultraå˜ä½“**: M3 Maxæœ‰40æ ¸ï¼
- **è¿”å›å€¼ä¸å‡†ç¡®**: åªåŒºåˆ†äº†M1/M2/M3åŸºç¡€ç‰ˆ
- **ç¼ºå°‘è¿è¡Œæ—¶æ£€æµ‹**: åº”è¯¥å°è¯•æŸ¥è¯¢å®é™…GPUæ ¸å¿ƒæ•°

### æ”¹è¿›æ–¹æ¡ˆ
```cpp
int get_gpu_core_count() {
#ifdef __APPLE__
  // å°è¯•é€šè¿‡Metal APIè·å–å®é™…GPUæ ¸å¿ƒæ•°
  // è¿™éœ€è¦æ·»åŠ Metal frameworkä¾èµ–
  // æš‚æ—¶ä½¿ç”¨sysctlå’Œæ¨¡å‹è¯†åˆ«
  
  char model[256];
  size_t len = sizeof(model);
  if (sysctlbyname("hw.model", model, &len, NULL, 0) == 0) {
    std::string model_str(model);
    
    // M1ç³»åˆ—
    if (model_str.find("Mac13,") != std::string::npos) {
      if (model_str.find("Mac13,2") != std::string::npos) {
        return 8;   // M1 Pro (14/16 cores)
      } else if (model_str.find("Mac13,1") != std::string::npos) {
        return 32;  // M1 Max (24/32 cores)
      }
      return 7;  // M1 (7/8 cores)
    }
    
    // M2ç³»åˆ—
    if (model_str.find("Mac14,") != std::string::npos) {
      if (model_str.find("Mac14,5") != std::string::npos ||
          model_str.find("Mac14,9") != std::string::npos) {
        return 19;  // M2 Pro (16/19 cores)
      } else if (model_str.find("Mac14,6") != std::string::npos) {
        return 38;  // M2 Max (30/38 cores)
      }
      return 10;  // M2 (8/10 cores)
    }
    
    // M3ç³»åˆ—
    if (model_str.find("Mac15,") != std::string::npos) {
      if (model_str.find("Mac15,3") != std::string::npos ||
          model_str.find("Mac15,6") != std::string::npos) {
        return 18;  // M3 Pro (14/18 cores)
      } else if (model_str.find("Mac15,7") != std::string::npos ||
          model_str.find("Mac15,11") != std::string::npos) {
        return 40;  // M3 Max (30/40 cores)
      }
      return 10;  // M3 (10 cores)
    }
  }
  
  // å¤‡é€‰ï¼šå°è¯•ä½¿ç”¨IOKitæŸ¥è¯¢
  // TODO: æ·»åŠ IOKitå®ç°
  
  // é»˜è®¤å€¼
  return 10;
#else
  return 0;
#endif
}
```

**æ”¹è¿›æ•ˆæœ**: èƒ½å¤Ÿè¯†åˆ«Pro/Maxå˜ä½“ï¼Œæ›´å‡†ç¡®çš„GPUæ ¸å¿ƒæ•°

---

## ğŸŸ¢ é¢å¤–ä¼˜åŒ–å»ºè®®

### 1. æ·»åŠ Adaptiveæœç´¢ç­–ç•¥

```cpp
// æ ¹æ®åˆæ­¥ç»“æœåŠ¨æ€è°ƒæ•´æœç´¢ç©ºé—´
std::vector<CandidateConfig> generate_adaptive_candidates(
    kernel::Graph const &graph,
    std::vector<CandidateConfig> const &initial_results) {
  
  // åˆ†ætop 10%é…ç½®çš„ç‰¹å¾
  auto top_configs = get_top_k_configs(initial_results, 
                                       initial_results.size() / 10);
  
  // æå–å…±åŒç‰¹å¾
  int avg_threadgroup = 0;
  int avg_tile_m = 0, avg_tile_n = 0, avg_tile_k = 0;
  
  for (auto const &config : top_configs) {
    auto *mps_cfg = static_cast<kernel::mps::MPSKernelConfig*>(
        config.config.get());
    avg_threadgroup += mps_cfg->threads_per_threadgroup;
    avg_tile_m += mps_cfg->tile_m;
    avg_tile_n += mps_cfg->tile_n;
    avg_tile_k += mps_cfg->tile_k;
  }
  
  int n = top_configs.size();
  avg_threadgroup /= n;
  avg_tile_m /= n;
  avg_tile_n /= n;
  avg_tile_k /= n;
  
  // åœ¨æœ€ä¼˜å€¼é™„è¿‘ç”Ÿæˆæ›´å¤šå€™é€‰
  return generate_fine_grained_candidates(
      avg_threadgroup, avg_tile_m, avg_tile_n, avg_tile_k);
}
```

### 2. è€ƒè™‘Dynamic Caching (M3+ç‰¹æ€§)

```cpp
// M3å¼•å…¥äº†Dynamic Caching - GPUå†…å­˜å¯ä»¥æŒ‰éœ€åˆ†é…ç»™ä¸åŒä»»åŠ¡
float evaluate_for_m3_dynamic_caching(
    kernel::mps::MPSKernelConfig const &config) {
  
  if (config.gpu_family < 9) {  // M3 = family 9
    return 1.0f;  // ä¸å½±å“æ—§èŠ¯ç‰‡
  }
  
  // M3çš„Dynamic Cachingå…è®¸æ›´çµæ´»çš„å†…å­˜ä½¿ç”¨
  // åå¥½è¾ƒå¤§çš„threadgroupä»¥å……åˆ†åˆ©ç”¨è¿™ä¸ªç‰¹æ€§
  float bonus = 1.0f;
  if (config.threads_per_threadgroup >= 256) {
    bonus = 1.15f;  // M3åœ¨å¤§threadgroupä¸Šè¡¨ç°æ›´å¥½
  }
  
  return bonus;
}
```

### 3. å®ç°Profile-guidedä¼˜åŒ–

```cpp
// è®°å½•å®é™…è¿è¡Œç»“æœï¼Œç”¨äºfutureä¼˜åŒ–
class MPSProfiler {
  struct ProfileEntry {
    MPSKernelConfig config;
    float actual_time_ms;
    float estimated_score;
    size_t problem_size;
  };
  
  std::vector<ProfileEntry> history_;
  
public:
  void record_result(MPSKernelConfig const &cfg, 
                    float time, float score, size_t size) {
    history_.push_back({cfg, time, score, size});
  }
  
  // ä¸ºç›¸ä¼¼é—®é¢˜æä¾›å»ºè®®é…ç½®
  MPSKernelConfig suggest_config(size_t problem_size) {
    // æŸ¥æ‰¾ç›¸ä¼¼é—®é¢˜çš„æœ€ä½³é…ç½®
    auto similar = find_similar_problems(problem_size);
    return get_best_config(similar);
  }
};
```

---

## ğŸ“Š ä¸CUDAç­–ç•¥å¯¹æ¯”

| ç‰¹æ€§ | CUDAç­–ç•¥ | MPSç­–ç•¥(å½“å‰) | MPSç­–ç•¥(å»ºè®®) |
|------|----------|---------------|---------------|
| **å€™é€‰æ•°é‡** | å‡ ç™¾ä¸ª | ~16ä¸ª | ~100-200ä¸ª |
| **Threadgroupé…ç½®** | 4-32 warps | 4ç§å¤§å° | 10-20ç§å¤§å° |
| **Tileé…ç½®** | å¤šç§Tensor Coreé…ç½® | 4ç§å›ºå®štile | å‡ åç§åŠ¨æ€tile |
| **GPUå˜ä½“è¯†åˆ«** | é€šè¿‡compute capability | åŸºç¡€è¯†åˆ«M1/M2/M3 | è¯†åˆ«Pro/Max/Ultra |
| **å†…å­˜ä¼˜åŒ–** | Shared memoryè€ƒè™‘å……åˆ† | åŸºç¡€è€ƒè™‘ | ç»Ÿä¸€å†…å­˜ä¼˜åŒ– |
| **Occupancy** | è¯¦ç»†è®¡ç®— | ç®€åŒ–è®¡ç®— | æ”¹è¿›è®¡ç®— |
| **Adaptiveæœç´¢** | æ—  | æ—  | å»ºè®®æ·»åŠ  |

---

## ğŸ¯ ä¼˜å…ˆçº§æ”¹è¿›è·¯çº¿å›¾

### é˜¶æ®µ1: åŸºç¡€ä¿®å¤ (ç«‹å³)
1. âœ… ä¿®æ­£threadgroup memoryè®¡ç®—ï¼ˆæ•°æ®ç±»å‹ï¼‰
2. âœ… æ”¹è¿›tileé…ç½®ç”Ÿæˆï¼ˆè€ƒè™‘å†…å­˜é™åˆ¶ï¼‰
3. âœ… å¢åŠ threadgroupå€™é€‰æ•°é‡

### é˜¶æ®µ2: å‡†ç¡®æ€§æå‡ (çŸ­æœŸ)
1. â³ æ”¹è¿›GPUæ ¸å¿ƒæ•°æ£€æµ‹ï¼ˆè¯†åˆ«Pro/Max/Ultraï¼‰
2. â³ ä¼˜åŒ–GPUåˆ©ç”¨ç‡è¯„ä¼°ï¼ˆå®é™…å¹¶å‘ç‰¹æ€§ï¼‰
3. â³ å¢å¼ºå†…å­˜æ•ˆç‡è¯„ä¼°ï¼ˆç»Ÿä¸€å†…å­˜æ¶æ„ï¼‰

### é˜¶æ®µ3: é«˜çº§ä¼˜åŒ– (ä¸­æœŸ)
1. ğŸ“‹ å®ç°adaptiveæœç´¢ç­–ç•¥
2. ğŸ“‹ æ·»åŠ M3 Dynamic Cachingæ”¯æŒ
3. ğŸ“‹ å®ç°profile-guidedä¼˜åŒ–

### é˜¶æ®µ4: ç”Ÿäº§å°±ç»ª (é•¿æœŸ)
1. ğŸ“‹ æ·»åŠ Metal APIç›´æ¥æŸ¥è¯¢
2. ğŸ“‹ å®ç°è¿è¡Œæ—¶auto-tuning
3. ğŸ“‹ å»ºç«‹benchmarkæ•°æ®åº“

---

## ğŸ’¡ æ€»ç»“

å½“å‰MPSæœç´¢ç­–ç•¥**åŸºç¡€æ­£ç¡®ä½†éœ€è¦å¤§å¹…æ”¹è¿›**ï¼š

### âœ… ä¼˜åŠ¿
- æ­£ç¡®ç†è§£Apple SiliconåŸºç¡€æ¶æ„
- å¤šç»´åº¦è¯„ä¼°æ¡†æ¶åˆç†
- åŸºç¡€éªŒè¯é€»è¾‘æ­£ç¡®

### âŒ ä¸è¶³
- æœç´¢ç©ºé—´å¤ªå°ï¼ˆ16ä¸ªå€™é€‰ vs CUDAçš„å‡ ç™¾ä¸ªï¼‰
- GPUç‰¹æ€§ç†è§£ä¸å¤Ÿæ·±å…¥ï¼ˆå¿½ç•¥Pro/Max/Ultraå·®å¼‚ï¼‰
- ç»Ÿä¸€å†…å­˜æ¶æ„ä¼˜åŠ¿æœªå……åˆ†åˆ©ç”¨
- è¯„ä¼°æŒ‡æ ‡æœ‰è®¡ç®—é”™è¯¯

### ğŸ¯ æ”¹è¿›æ•ˆæœé¢„æœŸ
å®æ–½ä¸Šè¿°æ”¹è¿›åï¼š
- **æœç´¢ç©ºé—´**: 16ä¸ª â†’ 100-200ä¸ªå€™é€‰
- **å‡†ç¡®æ€§**: +30-50% æ€§èƒ½æå‡
- **é€‚é…æ€§**: è‡ªåŠ¨é€‚åº”æ‰€æœ‰Mç³»åˆ—å˜ä½“
- **æ•ˆç‡**: Profile-guidedä¼˜åŒ–æŒç»­æ”¹è¿›

**å»ºè®®ä¼˜å…ˆå®æ–½é˜¶æ®µ1å’Œé˜¶æ®µ2çš„æ”¹è¿›ï¼**

