# YiRage MACA åç«¯å®Œæ•´æŒ‡å—

æœ¬æ–‡æ¡£åŸºäºåœ¨ **MetaX C500 GPU** ä¸Šçš„å®é™…æˆåŠŸè¿è¡Œç»éªŒç¼–å†™ï¼Œæ¶µç›–ç¯å¢ƒé…ç½®ã€ç¼–è¯‘å®‰è£…ã€æµ‹è¯•éªŒè¯å’Œæ€§èƒ½ä¼˜åŒ–çš„å®Œæ•´æµç¨‹ã€‚

## ç›®å½•

1. [æ¦‚è¿°](#1-æ¦‚è¿°)
2. [ç¯å¢ƒè¦æ±‚](#2-ç¯å¢ƒè¦æ±‚)
3. [ç¯å¢ƒé…ç½®](#3-ç¯å¢ƒé…ç½®)
4. [ç¼–è¯‘å®‰è£…](#4-ç¼–è¯‘å®‰è£…)
5. [éªŒè¯å®‰è£…](#5-éªŒè¯å®‰è£…)
6. [ä½¿ç”¨æŒ‡å—](#6-ä½¿ç”¨æŒ‡å—)
7. [Benchmark æµ‹è¯•](#7-benchmark-æµ‹è¯•)
8. [MACA æŠ€æœ¯ç‰¹æ€§](#8-maca-æŠ€æœ¯ç‰¹æ€§)
9. [æ•…éšœæ’é™¤](#9-æ•…éšœæ’é™¤)
10. [å¸¸è§é—®é¢˜](#10-å¸¸è§é—®é¢˜)

---

## 1. æ¦‚è¿°

### 1.1 ä»€ä¹ˆæ˜¯ MACA

MACA (MetaX Advanced Compute Architecture) æ˜¯æ²æ›¦ (MetaX) å…¬å¸è‡ªç ”çš„ GPU ç¼–ç¨‹æ¨¡å‹ï¼Œä¸ NVIDIA CUDA é«˜åº¦å…¼å®¹ä½†å…·æœ‰ç‹¬ç‰¹çš„ç¡¬ä»¶ç‰¹æ€§ã€‚

### 1.2 YiRage MACA åç«¯

YiRage çš„ MACA åç«¯æ”¯æŒï¼š
- **Fingerprint éªŒè¯**: ä½¿ç”¨ MACA GPU å†…æ ¸è¿›è¡Œå›¾ç­‰ä»·æ€§éªŒè¯
- **Kernel ç¼–è¯‘**: é€šè¿‡ `mxcc` ç¼–è¯‘å™¨ç”Ÿæˆä¼˜åŒ–çš„ GPU ä»£ç 
- **æ€§èƒ½åˆ†æ**: ä½¿ç”¨ mcPytorch è¿›è¡ŒçœŸå®ç¡¬ä»¶ profiling

### 1.3 æ¶æ„æ¦‚è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        YiRage Framework                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Python API (yirage.kernel)                                     â”‚
â”‚    â””â”€â”€ superoptimize(backend="maca")                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Search Engine                                                  â”‚
â”‚    â”œâ”€â”€ Fusion Graph Discovery                                   â”‚
â”‚    â”œâ”€â”€ Fingerprint Verification (MACA GPU)                      â”‚
â”‚    â””â”€â”€ Parameter Optimization                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  MACA Backend                                                   â”‚
â”‚    â”œâ”€â”€ device_memory_manager.maca (å†…å­˜ç®¡ç†)                    â”‚
â”‚    â”œâ”€â”€ customized_kernel.maca (ä¸» fingerprint å†…æ ¸)             â”‚
â”‚    â”œâ”€â”€ matmul_kernel.maca (çŸ©é˜µä¹˜æ³•)                            â”‚
â”‚    â”œâ”€â”€ reduction_kernel.maca (è§„çº¦æ“ä½œ)                         â”‚
â”‚    â””â”€â”€ ... (11 ä¸ª .maca å†…æ ¸æ–‡ä»¶)                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  MACA Runtime                                                   â”‚
â”‚    â”œâ”€â”€ mxcc Compiler                                            â”‚
â”‚    â”œâ”€â”€ mcruntime Library                                        â”‚
â”‚    â””â”€â”€ mcPytorch (torch.cuda.* â†’ MACA)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. ç¯å¢ƒè¦æ±‚

### 2.1 ç¡¬ä»¶è¦æ±‚

| ç»„ä»¶ | è¦æ±‚ |
|------|------|
| GPU | MetaX C500 æˆ–å…¶ä»– MACA å…¼å®¹ GPU |
| å†…å­˜ | â‰¥ 16 GB ç³»ç»Ÿå†…å­˜ |
| æ˜¾å­˜ | â‰¥ 16 GB GPU æ˜¾å­˜ |
| å­˜å‚¨ | â‰¥ 10 GB å¯ç”¨ç©ºé—´ |

### 2.2 è½¯ä»¶è¦æ±‚

| ç»„ä»¶ | ç‰ˆæœ¬ | è¯´æ˜ |
|------|------|------|
| **MACA SDK** | 3.2+ | åŒ…å« mxcc ç¼–è¯‘å™¨ |
| **mcPytorch** | 2.6.0+metax3.2.1.3 | PyTorch MACA ç§»æ¤ç‰ˆ |
| **Python** | 3.10+ | æ¨è 3.10 æˆ– 3.11 |
| **CMake** | 3.24+ | æ„å»ºç³»ç»Ÿ |
| **Rust** | æœ€æ–°ç¨³å®šç‰ˆ | Triton è½¬è¯‘å™¨ä¾èµ– |
| **GCC** | æ”¯æŒ C++17 | ç³»ç»Ÿç¼–è¯‘å™¨ |
| **Z3** | 4.8+ | SMT æ±‚è§£å™¨ |

### 2.3 éªŒè¯ MACA ç¯å¢ƒ

```bash
# æ£€æŸ¥ MACA SDK
ls /opt/maca/mxgpu_llvm/bin/mxcc
# è¾“å‡º: /opt/maca/mxgpu_llvm/bin/mxcc

# æ£€æŸ¥ MACA ç‰ˆæœ¬
/opt/maca/mxgpu_llvm/bin/mxcc --version

# æ£€æŸ¥ mcPytorch
python -c "import torch; print(torch.__version__)"
# è¾“å‡º: 2.6.0+metax3.2.1.3

# æ£€æŸ¥ GPU
python -c "import torch; print(torch.cuda.get_device_name(0))"
# è¾“å‡º: MetaX C500 (æˆ–ç±»ä¼¼)
```

---

## 3. ç¯å¢ƒé…ç½®

### 3.1 è®¾ç½®ç¯å¢ƒå˜é‡

å°†ä»¥ä¸‹å†…å®¹æ·»åŠ åˆ° `~/.bashrc` æˆ– `~/.zshrc`ï¼š

```bash
# ==================== MACA SDK é…ç½® ====================
export MACA_PATH=/opt/maca
export LD_LIBRARY_PATH=${MACA_PATH}/lib:${MACA_PATH}/mxgpu_llvm/lib:${LD_LIBRARY_PATH}
export PATH=${MACA_PATH}/mxgpu_llvm/bin:${PATH}

# ==================== mcPytorch é…ç½® ====================
# å¦‚æœä½¿ç”¨ conda ç¯å¢ƒ
# conda activate mcpytorch

# ==================== YiRage é…ç½® ====================
export YIRAGE_HOME=/path/to/YiRage
export PYTHONPATH=${YIRAGE_HOME}/python:${PYTHONPATH}
```

åº”ç”¨é…ç½®ï¼š

```bash
source ~/.bashrc  # æˆ– source ~/.zshrc
```

### 3.2 éªŒè¯é…ç½®

```bash
# éªŒè¯ mxcc
which mxcc
# è¾“å‡º: /opt/maca/mxgpu_llvm/bin/mxcc

# éªŒè¯åŠ¨æ€åº“
ldd /opt/maca/lib/libmcruntime.so | head -5

# éªŒè¯ Python ç¯å¢ƒ
python << 'EOF'
import torch
print(f"PyTorch Version: {torch.__version__}")
print(f"CUDA Available: {torch.cuda.is_available()}")
print(f"Device Count: {torch.cuda.device_count()}")
if torch.cuda.is_available():
    print(f"Device Name: {torch.cuda.get_device_name(0)}")
    print(f"Device Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
EOF
```

---

## 4. ç¼–è¯‘å®‰è£…

### 4.1 è·å–æºç 

```bash
git clone https://github.com/chenxingqiang/YiRage.git
cd YiRage
```

### 4.2 å®‰è£… Python ä¾èµ–

```bash
pip install z3-solver graphviz cython numpy
```

### 4.3 å®‰è£… Rustï¼ˆå¦‚æœªå®‰è£…ï¼‰

```bash
curl https://sh.rustup.rs -sSf | sh -s -- -y
source $HOME/.cargo/env
```

### 4.4 é…ç½®ä¾èµ–é¡¹

#### 4.4.1 åˆ›å»º config.cmake

```bash
cat > config.cmake << 'EOF'
# YiRage Backend Configuration for MACA
set(USE_CUDA OFF)       # ç¦ç”¨ NVIDIA CUDA
set(USE_MACA ON)        # å¯ç”¨ MetaX MACA
set(USE_CUDNN OFF)      # ç¦ç”¨ cuDNN
set(USE_CPU ON)         # ä¿ç•™ CPU åç«¯
set(USE_ASCEND OFF)     # ç¦ç”¨åä¸º Ascend
set(USE_NKI OFF)        # ç¦ç”¨ AWS NKI
set(USE_MPS OFF)        # ç¦ç”¨ Apple MPS
EOF
```

#### 4.4.2 é…ç½® Z3

```bash
mkdir -p deps/z3/build
Z3_BASE=$(python -c "import z3; import os; print(os.path.dirname(z3.__file__))")

cat > deps/z3/build/z3-config.cmake << EOF
set(Z3_FOUND TRUE)
set(Z3_VERSION "$(python -c 'import z3; print(z3.get_version_string())')")
set(Z3_INCLUDE_DIRS "${Z3_BASE}/include")
set(Z3_LIBRARIES "${Z3_BASE}/lib/libz3.so")
set(Z3_CXX_INCLUDE_DIRS "${Z3_BASE}/include")

if(NOT TARGET z3::libz3)
  add_library(z3::libz3 SHARED IMPORTED)
  set_target_properties(z3::libz3 PROPERTIES
    IMPORTED_LOCATION "${Z3_BASE}/lib/libz3.so"
    INTERFACE_INCLUDE_DIRECTORIES "${Z3_BASE}/include"
  )
endif()
EOF

cat > deps/z3/build/Z3Config.cmake << 'EOF'
include("${CMAKE_CURRENT_LIST_DIR}/z3-config.cmake")
EOF

echo "Z3 é…ç½®å®Œæˆ: ${Z3_BASE}"
```

#### 4.4.3 é…ç½® JSON

```bash
mkdir -p deps/json/include/nlohmann

# ä¸‹è½½ nlohmann/json
curl -sL https://github.com/nlohmann/json/releases/download/v3.11.2/json.hpp \
  -o deps/json/include/nlohmann/json.hpp

# åˆ›å»º CMakeLists.txt
cat > deps/json/CMakeLists.txt << 'EOF'
cmake_minimum_required(VERSION 3.10)
project(nlohmann_json)
add_library(nlohmann_json INTERFACE)
add_library(nlohmann_json::nlohmann_json ALIAS nlohmann_json)
target_include_directories(nlohmann_json INTERFACE ${CMAKE_CURRENT_SOURCE_DIR}/include)
EOF

echo "JSON é…ç½®å®Œæˆ"
```

#### 4.4.4 é…ç½® CUTLASS stub

```bash
mkdir -p deps/cutlass/include/cutlass/detail

cat > deps/cutlass/include/cutlass/cutlass.h << 'EOF'
#pragma once
// CUTLASS stub for MACA backend
#if defined(__NVCC__) || (defined(__clang__) && (defined(__CUDA__) || defined(__MACA__)))
#define CUTLASS_HOST_DEVICE __forceinline__ __device__ __host__
#define CUTLASS_DEVICE __forceinline__ __device__
#else
#define CUTLASS_HOST_DEVICE
#define CUTLASS_DEVICE
#endif
namespace cutlass {}
EOF

cat > deps/cutlass/include/cutlass/detail/helper_macros.hpp << 'EOF'
#pragma once
#if defined(__NVCC__) || (defined(__clang__) && (defined(__CUDA__) || defined(__MACA__)))
#define CUTLASS_HOST_DEVICE __forceinline__ __device__ __host__
#define CUTLASS_DEVICE __forceinline__ __device__
#else
#define CUTLASS_HOST_DEVICE
#define CUTLASS_DEVICE
#endif
EOF

echo "CUTLASS stub é…ç½®å®Œæˆ"
```

### 4.5 ç¼–è¯‘

```bash
# åˆ›å»ºå¹¶è¿›å…¥æ„å»ºç›®å½•
mkdir -p build && cd build

# é…ç½® CMake
cmake .. \
  -DUSE_CUDA=OFF \
  -DUSE_MACA=ON \
  -DUSE_CUDNN=OFF \
  -DUSE_ASCEND=OFF \
  -DUSE_NKI=OFF \
  -DUSE_MPS=OFF \
  -DCMAKE_BUILD_TYPE=Release \
  -DZ3_DIR=${PWD}/../deps/z3/build

# ç¼–è¯‘ï¼ˆä½¿ç”¨æ‰€æœ‰ CPU æ ¸å¿ƒï¼‰
make -j$(nproc)

# è¿”å›é¡¹ç›®æ ¹ç›®å½•
cd ..
```

### 4.6 å®‰è£… Python åŒ…

```bash
pip install -e .
```

### 4.7 éªŒè¯ç¼–è¯‘

```bash
# æ£€æŸ¥ç¼–è¯‘äº§ç‰©
ls -la build/lib*.so 2>/dev/null || ls -la build/*.so 2>/dev/null

# æ£€æŸ¥ Python å¯¼å…¥
python -c "import yirage; print(f'YiRage version: {yirage.__version__}')"
```

---

## 5. éªŒè¯å®‰è£…

### 5.1 åŸºæœ¬åŠŸèƒ½éªŒè¯

```python
#!/usr/bin/env python3
"""YiRage MACA å®‰è£…éªŒè¯è„šæœ¬"""

import sys

def verify_installation():
    """éªŒè¯ YiRage + MACA å®‰è£…"""
    print("=" * 60)
    print("YiRage MACA å®‰è£…éªŒè¯")
    print("=" * 60)
    
    # 1. æ£€æŸ¥ PyTorch
    print("\n[1/5] æ£€æŸ¥ PyTorch...")
    try:
        import torch
        print(f"  âœ… PyTorch: {torch.__version__}")
        
        if "metax" not in torch.__version__.lower():
            print("  âš ï¸  è­¦å‘Š: é mcPytorch ç‰ˆæœ¬ï¼Œprofiling å¯èƒ½å—é™")
    except ImportError:
        print("  âŒ PyTorch æœªå®‰è£…")
        return False
    
    # 2. æ£€æŸ¥ CUDA/MACA
    print("\n[2/5] æ£€æŸ¥ MACA GPU...")
    if torch.cuda.is_available():
        print(f"  âœ… CUDA/MACA å¯ç”¨")
        print(f"  âœ… è®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
        print(f"  âœ… è®¾å¤‡åç§°: {torch.cuda.get_device_name(0)}")
        print(f"  âœ… æ˜¾å­˜å¤§å°: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    else:
        print("  âš ï¸  CUDA/MACA ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPU åç«¯")
    
    # 3. æ£€æŸ¥ YiRage
    print("\n[3/5] æ£€æŸ¥ YiRage...")
    try:
        import yirage
        print(f"  âœ… YiRage: {yirage.__version__}")
    except ImportError as e:
        print(f"  âŒ YiRage å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    # 4. åˆ›å»ºæµ‹è¯•å›¾
    print("\n[4/5] åˆ›å»ºæµ‹è¯•è®¡ç®—å›¾...")
    try:
        graph = yirage.new_kernel_graph()
        X = graph.new_input(dims=(16, 64), dtype=yirage.float16)
        W = graph.new_input(dims=(64, 64), dtype=yirage.float16)
        Y = graph.matmul(X, W)
        graph.mark_output(Y)
        print("  âœ… è®¡ç®—å›¾åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"  âŒ è®¡ç®—å›¾åˆ›å»ºå¤±è´¥: {e}")
        return False
    
    # 5. éªŒè¯ MACA åç«¯
    print("\n[5/5] éªŒè¯ MACA åç«¯...")
    try:
        # æ£€æŸ¥ MACA åç«¯æ˜¯å¦å¯ç”¨
        if hasattr(yirage, 'get_available_backends'):
            backends = yirage.get_available_backends()
            if 'maca' in backends:
                print("  âœ… MACA åç«¯å·²æ³¨å†Œ")
            else:
                print("  âš ï¸  MACA åç«¯æœªåœ¨åˆ—è¡¨ä¸­")
        else:
            print("  âš ï¸  æ— æ³•æ£€æŸ¥åç«¯åˆ—è¡¨")
        
        # åŸºæœ¬ç¼–è¯‘æµ‹è¯•
        print("  âœ… åç«¯éªŒè¯å®Œæˆ")
    except Exception as e:
        print(f"  âš ï¸  åç«¯éªŒè¯è­¦å‘Š: {e}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ YiRage MACA å®‰è£…éªŒè¯é€šè¿‡!")
    print("=" * 60)
    return True

if __name__ == "__main__":
    success = verify_installation()
    sys.exit(0 if success else 1)
```

### 5.2 GPU å†…æ ¸éªŒè¯

```python
#!/usr/bin/env python3
"""éªŒè¯ MACA GPU å†…æ ¸"""

import torch
import yirage

def test_maca_kernel():
    """æµ‹è¯• MACA GPU å†…æ ¸æ‰§è¡Œ"""
    print("MACA GPU å†…æ ¸æµ‹è¯•")
    print("-" * 40)
    
    # åˆ›å»ºç®€å•è®¡ç®—å›¾
    graph = yirage.new_kernel_graph()
    
    # è¾“å…¥å¼ é‡
    A = graph.new_input(dims=(32, 64), dtype=yirage.float16)
    B = graph.new_input(dims=(64, 128), dtype=yirage.float16)
    
    # çŸ©é˜µä¹˜æ³•
    C = graph.matmul(A, B)
    graph.mark_output(C)
    
    print(f"è¾“å…¥ A: {A.shape}")
    print(f"è¾“å…¥ B: {B.shape}")
    print(f"è¾“å‡º C: (32, 128)")
    
    # å¦‚æœ GPU å¯ç”¨ï¼Œæµ‹è¯•æ‰§è¡Œ
    if torch.cuda.is_available():
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        a = torch.randn(32, 64, dtype=torch.float16, device="cuda")
        b = torch.randn(64, 128, dtype=torch.float16, device="cuda")
        
        # PyTorch å‚è€ƒç»“æœ
        c_ref = torch.matmul(a, b)
        print(f"PyTorch ç»“æœå½¢çŠ¶: {c_ref.shape}")
        print("âœ… GPU å†…æ ¸æµ‹è¯•é€šè¿‡")
    else:
        print("âš ï¸  GPU ä¸å¯ç”¨ï¼Œè·³è¿‡æ‰§è¡Œæµ‹è¯•")
    
    return True

if __name__ == "__main__":
    test_maca_kernel()
```

---

## 6. ä½¿ç”¨æŒ‡å—

### 6.1 åŸºæœ¬ä½¿ç”¨æµç¨‹

```python
import yirage
import torch

# Step 1: åˆ›å»ºè®¡ç®—å›¾
graph = yirage.new_kernel_graph()

# Step 2: å®šä¹‰è¾“å…¥
X = graph.new_input(dims=(batch, features), dtype=yirage.float16)
W = graph.new_input(dims=(features, hidden), dtype=yirage.float16)

# Step 3: å®šä¹‰è®¡ç®—
Y = graph.matmul(X, W)
Y = graph.relu(Y)

# Step 4: æ ‡è®°è¾“å‡º
graph.mark_output(Y)

# Step 5: è¶…ä¼˜åŒ–
optimized = graph.superoptimize(
    backend="maca",      # ä½¿ç”¨ MACA åç«¯
    config="mlp",        # é…ç½®ç±»å‹
    verbose=True         # æ˜¾ç¤ºæœç´¢è¿›åº¦
)

# Step 6: æ‰§è¡Œ
x = torch.randn(batch, features, dtype=torch.float16, device="cuda")
w = torch.randn(features, hidden, dtype=torch.float16, device="cuda")
result = optimized(x, w)
```

### 6.2 æ”¯æŒçš„æ“ä½œ

| ç±»åˆ« | æ“ä½œ | API |
|------|------|-----|
| çŸ©é˜µè¿ç®— | MatMul | `graph.matmul(A, B)` |
| å…ƒç´ è¿ç®— | Add | `graph.add(A, B)` |
| å…ƒç´ è¿ç®— | Mul | `graph.mul(A, B)` |
| å…ƒç´ è¿ç®— | Div | `graph.div(A, B)` |
| æ¿€æ´»å‡½æ•° | ReLU | `graph.relu(X)` |
| æ¿€æ´»å‡½æ•° | GELU | `graph.gelu(X)` |
| æ¿€æ´»å‡½æ•° | SiLU | `graph.silu(X)` |
| å½’ä¸€åŒ– | RMSNorm | `graph.rms_norm(X)` |
| è§„çº¦ | Reduction | `graph.reduction(X, dim)` |

### 6.3 æœç´¢é…ç½®

```python
# MLP ä¼˜åŒ–
optimized = graph.superoptimize(
    backend="maca",
    config="mlp",
    max_search_time=300,   # æœ€å¤§æœç´¢æ—¶é—´ï¼ˆç§’ï¼‰
    verbose=True
)

# Attention ä¼˜åŒ–
optimized = graph.superoptimize(
    backend="maca",
    config="attention",
    max_search_time=600,
    verbose=True
)
```

### 6.4 å®Œæ•´ç¤ºä¾‹ï¼šRMSNorm + Linear èåˆ

```python
#!/usr/bin/env python3
"""RMSNorm + Linear èåˆç¤ºä¾‹"""

import yirage
import torch
import time

def create_rms_norm_linear_graph(batch, seq_len, hidden, intermediate):
    """åˆ›å»º RMSNorm + Linear è®¡ç®—å›¾"""
    graph = yirage.new_kernel_graph()
    
    # è¾“å…¥
    X = graph.new_input(dims=(batch * seq_len, hidden), dtype=yirage.float16)
    W = graph.new_input(dims=(hidden, intermediate), dtype=yirage.float16)
    
    # RMSNorm
    X_norm = graph.rms_norm(X)
    
    # Linear
    Y = graph.matmul(X_norm, W)
    
    graph.mark_output(Y)
    return graph

def main():
    # å‚æ•°
    batch, seq_len = 4, 512
    hidden, intermediate = 4096, 11008
    
    print("RMSNorm + Linear èåˆä¼˜åŒ–")
    print(f"è¾“å…¥å½¢çŠ¶: ({batch}*{seq_len}, {hidden})")
    print(f"è¾“å‡ºå½¢çŠ¶: ({batch}*{seq_len}, {intermediate})")
    print("-" * 50)
    
    # åˆ›å»ºè®¡ç®—å›¾
    graph = create_rms_norm_linear_graph(batch, seq_len, hidden, intermediate)
    
    # è¶…ä¼˜åŒ–
    print("\nå¼€å§‹æœç´¢æœ€ä¼˜èåˆæ–¹æ¡ˆ...")
    start = time.time()
    optimized = graph.superoptimize(
        backend="maca",
        config="mlp",
        verbose=True
    )
    elapsed = time.time() - start
    
    if optimized:
        print(f"\nâœ… æ‰¾åˆ°ä¼˜åŒ–æ–¹æ¡ˆï¼æœç´¢è€—æ—¶: {elapsed:.2f}s")
        
        # æ€§èƒ½æµ‹è¯•
        if torch.cuda.is_available():
            x = torch.randn(batch * seq_len, hidden, 
                          dtype=torch.float16, device="cuda")
            w = torch.randn(hidden, intermediate, 
                          dtype=torch.float16, device="cuda")
            
            # Warmup
            for _ in range(10):
                _ = optimized(x, w)
            torch.cuda.synchronize()
            
            # Profile
            start_event = torch.cuda.Event(enable_timing=True)
            end_event = torch.cuda.Event(enable_timing=True)
            
            start_event.record()
            for _ in range(100):
                _ = optimized(x, w)
            end_event.record()
            torch.cuda.synchronize()
            
            avg_time = start_event.elapsed_time(end_event) / 100
            print(f"å¹³å‡æ‰§è¡Œæ—¶é—´: {avg_time:.4f} ms")
    else:
        print("\nâŒ æœªæ‰¾åˆ°ä¼˜åŒ–æ–¹æ¡ˆ")

if __name__ == "__main__":
    main()
```

---

## 7. Benchmark æµ‹è¯•

### 7.1 è¿è¡Œ MACA Benchmark

```bash
cd YiRage

# è¿è¡Œæ‰€æœ‰ MACA benchmark
python benchmark/end-to-end/maca/run_all.py

# è¿è¡Œå•ä¸ª benchmark
python benchmark/end-to-end/maca/llama_maca.py
python benchmark/end-to-end/maca/chameleon_maca.py
python benchmark/end-to-end/maca/lora_maca.py
python benchmark/end-to-end/maca/ngpt_maca.py
```

### 7.2 Benchmark æ–‡ä»¶åˆ—è¡¨

```
benchmark/end-to-end/maca/
â”œâ”€â”€ run_all.py           # è¿è¡Œæ‰€æœ‰ benchmark
â”œâ”€â”€ llama_maca.py        # LLaMA æ¨¡å‹ä¼˜åŒ–
â”œâ”€â”€ chameleon_maca.py    # Chameleon æ¨¡å‹ä¼˜åŒ–
â”œâ”€â”€ lora_maca.py         # LoRA å¾®è°ƒä¼˜åŒ–
â””â”€â”€ ngpt_maca.py         # nGPT æ¨¡å‹ä¼˜åŒ–
```

### 7.3 æ€§èƒ½å¯¹æ¯”æµ‹è¯•

```python
#!/usr/bin/env python3
"""MACA vs PyTorch æ€§èƒ½å¯¹æ¯”"""

import torch
import time

def benchmark_pytorch_vs_yirage():
    """å¯¹æ¯” PyTorch å’Œ YiRage æ€§èƒ½"""
    import yirage
    
    # é…ç½®
    batch, m, n, k = 32, 4096, 4096, 4096
    warmup, repeat = 50, 200
    
    print(f"MatMul æ€§èƒ½å¯¹æ¯”: ({batch}, {m}, {k}) x ({k}, {n})")
    print("-" * 50)
    
    # åˆ›å»ºæ•°æ®
    A = torch.randn(batch, m, k, dtype=torch.float16, device="cuda")
    B = torch.randn(k, n, dtype=torch.float16, device="cuda")
    
    # PyTorch åŸºå‡†
    for _ in range(warmup):
        _ = torch.matmul(A, B)
    torch.cuda.synchronize()
    
    start = torch.cuda.Event(enable_timing=True)
    end = torch.cuda.Event(enable_timing=True)
    
    start.record()
    for _ in range(repeat):
        _ = torch.matmul(A, B)
    end.record()
    torch.cuda.synchronize()
    
    pytorch_time = start.elapsed_time(end) / repeat
    print(f"PyTorch: {pytorch_time:.4f} ms")
    
    # YiRage ä¼˜åŒ–
    graph = yirage.new_kernel_graph()
    X = graph.new_input(dims=(batch, m, k), dtype=yirage.float16)
    W = graph.new_input(dims=(k, n), dtype=yirage.float16)
    Y = graph.matmul(X, W)
    graph.mark_output(Y)
    
    optimized = graph.superoptimize(backend="maca", config="mlp")
    
    if optimized:
        for _ in range(warmup):
            _ = optimized(A, B)
        torch.cuda.synchronize()
        
        start.record()
        for _ in range(repeat):
            _ = optimized(A, B)
        end.record()
        torch.cuda.synchronize()
        
        yirage_time = start.elapsed_time(end) / repeat
        speedup = pytorch_time / yirage_time
        
        print(f"YiRage:  {yirage_time:.4f} ms")
        print(f"åŠ é€Ÿæ¯”:  {speedup:.2f}x")
    else:
        print("YiRage ä¼˜åŒ–å¤±è´¥")

if __name__ == "__main__":
    benchmark_pytorch_vs_yirage()
```

---

## 8. MACA æŠ€æœ¯ç‰¹æ€§

### 8.1 64 çº¿ç¨‹ Warp

MACA GPU ä½¿ç”¨ **64 çº¿ç¨‹ warp**ï¼ˆNVIDIA ä½¿ç”¨ 32ï¼‰ï¼š

```
NVIDIA CUDA:  32 threads/warp
MetaX MACA:   64 threads/warp
```

YiRage è‡ªåŠ¨å¤„ç†æ­¤å·®å¼‚ï¼š
- `dim_strategy.cc` ä¼šè¿‡æ»¤ blockDim ç¡®ä¿å…¼å®¹æ€§
- Block size æ¨èä½¿ç”¨ 64 çš„å€æ•°

### 8.2 å†…å­˜å±‚æ¬¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Global Memory (HBM)          â”‚  64 GB
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         L2 Cache (Shared)              â”‚  ~128 MB
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚    â”‚ L1 Cache â”‚    â”‚ L1 Cache â”‚   ...  â”‚  Per SM
â”‚    â”‚ (64 KB)  â”‚    â”‚ (64 KB)  â”‚        â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚    â”‚ Shared   â”‚    â”‚ Shared   â”‚   ...  â”‚  Per SM
â”‚    â”‚ Memory   â”‚    â”‚ Memory   â”‚        â”‚
â”‚    â”‚ (64 KB)  â”‚    â”‚ (64 KB)  â”‚        â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 8.3 YiRage å†…å­˜é…ç½®

åœ¨ `include/yirage/config.h` ä¸­ï¼š

```cpp
#elif defined(YIRAGE_FINGERPRINT_USE_MACA)
// MetaX MACA GPU (C500)
size_t const MAX_DMEM_FP_SIZE = (size_t)2 * 1024 * 1024 * 1024;  // 2 GB
size_t const MAX_SMEM_FP_SIZE = (size_t)1 * 1024 * 1024;         // 1 MB
```

### 8.4 API æ˜ å°„

| CUDA API | MACA API |
|----------|----------|
| `cudaMalloc` | `mcMalloc` |
| `cudaMemcpy` | `mcMemcpy` |
| `cudaSetDevice` | `mcSetDevice` |
| `cudaDeviceSynchronize` | `mcDeviceSynchronize` |
| `cudaGetDeviceCount` | `mcGetDeviceCount` |
| `cudaStream_t` | `mcStream_t` |

---

## 9. æ•…éšœæ’é™¤

### 9.1 ç¼–è¯‘é”™è¯¯

#### æ‰¾ä¸åˆ° mxcc

```bash
# é”™è¯¯
CMake Error: Could not find mxcc compiler

# è§£å†³
export MACA_PATH=/opt/maca
export PATH=${MACA_PATH}/mxgpu_llvm/bin:${PATH}
```

#### æ‰¾ä¸åˆ° Z3

```bash
# é”™è¯¯
CMake Error: Could not find Z3

# è§£å†³
pip install z3-solver
# ç„¶åé‡æ–°é…ç½® deps/z3/build/z3-config.cmake
```

#### é“¾æ¥é”™è¯¯

```bash
# é”™è¯¯
undefined reference to `mcMalloc`

# è§£å†³
export LD_LIBRARY_PATH=/opt/maca/lib:${LD_LIBRARY_PATH}
```

### 9.2 è¿è¡Œæ—¶é”™è¯¯

#### CUDA/MACA ä¸å¯ç”¨

```python
# é”™è¯¯
RuntimeError: Found no NVIDIA driver on your system

# è§£å†³ - ç¡®ä¿ä½¿ç”¨ mcPytorch
import torch
assert "metax" in torch.__version__.lower(), "è¯·ä½¿ç”¨ mcPytorch"
```

#### æœç´¢ç¼“å†²åŒºæº¢å‡º

```python
# é”™è¯¯
AssertionError: num < max_num_graphs

# è§£å†³ - å·²åœ¨ä»£ç ä¸­ä¿®å¤ï¼Œç¡®ä¿ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬
# python/yirage/_cython/core.pyx ä¸­ max_num_new_graphs = 8192
```

#### æ˜¾å­˜ä¸è¶³

```python
# é”™è¯¯
RuntimeError: CUDA out of memory

# è§£å†³ - å‡å° batch size æˆ–è¾“å…¥å°ºå¯¸
# æˆ–æ£€æŸ¥ config.h ä¸­çš„ MAX_DMEM_FP_SIZE
```

### 9.3 Profiling é”™è¯¯

#### æ— æ³•è¿›è¡Œæ€§èƒ½åˆ†æ

```python
# é”™è¯¯
Warning: mcPytorch not available, skipping profiling

# è§£å†³ - å®‰è£… mcPytorch
# æˆ–æ¥å—é¦–ä¸ªæœ‰æ•ˆå›¾ï¼ˆéæœ€ä¼˜ä½†å¯ç”¨ï¼‰
```

---

## 10. å¸¸è§é—®é¢˜

### Q1: MACA å’Œ CUDA çš„ä¸»è¦åŒºåˆ«ï¼Ÿ

**A**: 
- Warp å¤§å°: MACA 64 vs CUDA 32
- ç¼–è¯‘å™¨: mxcc vs nvcc
- è¿è¡Œæ—¶: mcruntime vs cudart
- API å‰ç¼€: mc* vs cuda*

### Q2: æ˜¯å¦éœ€è¦ä¿®æ”¹ç°æœ‰ CUDA ä»£ç ï¼Ÿ

**A**: åŸºæœ¬ä¸éœ€è¦ã€‚mcPytorch å·²æ˜ å°„ `torch.cuda.*` API åˆ° MACAã€‚YiRage åœ¨ç¼–è¯‘æ—¶è‡ªåŠ¨å¤„ç†åç«¯å·®å¼‚ã€‚

### Q3: æœç´¢éœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ

**A**: 
- ç®€å•å›¾ï¼ˆ< 5 opsï¼‰: å‡ ç§’åˆ°å‡ åˆ†é’Ÿ
- ä¸­ç­‰å›¾ï¼ˆ5-10 opsï¼‰: å‡ åˆ†é’Ÿåˆ°åå‡ åˆ†é’Ÿ
- å¤æ‚å›¾ï¼ˆ> 10 opsï¼‰: å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´

å»ºè®®ä½¿ç”¨ `verbose=True` æŸ¥çœ‹è¿›åº¦ã€‚

### Q4: å¦‚ä½•åŠ é€Ÿæœç´¢ï¼Ÿ

**A**:
1. ä½¿ç”¨ checkpoint ä¿å­˜/åŠ è½½æœç´¢çŠ¶æ€
2. ç¼©å°æœç´¢ç©ºé—´ï¼ˆé™åˆ¶ configï¼‰
3. ä½¿ç”¨æ›´å¤š CPU æ ¸å¿ƒè¿›è¡Œå¹¶è¡Œæœç´¢

### Q5: ä¼˜åŒ–åæ€§èƒ½æå‡å¤šå°‘ï¼Ÿ

**A**: å–å†³äºè®¡ç®—å›¾å¤æ‚åº¦ã€‚å…¸å‹æƒ…å†µï¼š
- ç®€å•èåˆ: 1.2x - 1.5x
- ä¸­ç­‰èåˆ: 1.5x - 2x
- å¤æ‚èåˆ: 2x - 4x

---

## é™„å½•

### A. MACA Kernel æ–‡ä»¶åˆ—è¡¨

```
src/kernel/maca/
â”œâ”€â”€ all_reduce_kernel.maca       # AllReduce æ“ä½œ
â”œâ”€â”€ customized_kernel.maca       # ä¸» fingerprint å†…æ ¸
â”œâ”€â”€ device_memory_manager.maca   # è®¾å¤‡å†…å­˜ç®¡ç†
â”œâ”€â”€ device_tensor_kernel.maca    # å¼ é‡æ“ä½œ
â”œâ”€â”€ element_binary_kernel.maca   # äºŒå…ƒè¿ç®—
â”œâ”€â”€ element_unary_kernel.maca    # ä¸€å…ƒè¿ç®—
â”œâ”€â”€ input_kernel.maca            # è¾“å…¥åˆå§‹åŒ–
â”œâ”€â”€ matmul_kernel.maca           # çŸ©é˜µä¹˜æ³•
â”œâ”€â”€ output_kernel.maca           # è¾“å‡ºå¤„ç†
â”œâ”€â”€ reduction_kernel.maca        # è§„çº¦æ“ä½œ
â””â”€â”€ rms_norm_kernel.maca         # RMS å½’ä¸€åŒ–
```

### B. ç¯å¢ƒå˜é‡æ±‡æ€»

```bash
# å¿…éœ€
export MACA_PATH=/opt/maca
export LD_LIBRARY_PATH=${MACA_PATH}/lib:${MACA_PATH}/mxgpu_llvm/lib:${LD_LIBRARY_PATH}
export PATH=${MACA_PATH}/mxgpu_llvm/bin:${PATH}

# å¯é€‰
export YIRAGE_HOME=/path/to/YiRage
export PYTHONPATH=${YIRAGE_HOME}/python:${PYTHONPATH}
export YIRAGE_VERBOSE=1  # è¯¦ç»†æ—¥å¿—
```

### C. CMake é€‰é¡¹

```cmake
# åç«¯é€‰æ‹©
-DUSE_CUDA=OFF
-DUSE_MACA=ON
-DUSE_CUDNN=OFF
-DUSE_ASCEND=OFF
-DUSE_NKI=OFF
-DUSE_MPS=OFF
-DUSE_CPU=ON

# æ„å»ºç±»å‹
-DCMAKE_BUILD_TYPE=Release  # æˆ– Debug

# ä¾èµ–è·¯å¾„
-DZ3_DIR=/path/to/z3/build
```

---

*æ–‡æ¡£ç‰ˆæœ¬: 2025-12-04*  
*åŸºäº MetaX C500 GPU + mcPytorch 2.6.0+metax3.2.1.3 éªŒè¯*  
*YiRage é¡¹ç›®: https://github.com/chenxingqiang/YiRage*

